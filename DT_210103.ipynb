# Part 0: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, roc_curve
)

# Part 1: Load heart.csv
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/heart.csv")
print(df.shape)
df.head()

# Part 2: Inspect dataset
print(df.columns)
print(df.dtypes)
print("\nMissing values:\n", df.isnull().sum())
df.describe()

# Part 3: Separate X and y
target_col = "target"

X = df.drop(target_col, axis=1)
y = df[target_col]

print("X shape:", X.shape)
print("y shape:", y.shape)
y.value_counts()

# Part 4: Train / Validation / Test split
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print("Train:", X_train.shape)
print("Validation:", X_val.shape)
print("Test:", X_test.shape)

# Part 5: Handle missing values
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="median")

X_train_imp = imputer.fit_transform(X_train)
X_val_imp   = imputer.transform(X_val)
X_test_imp  = imputer.transform(X_test)

print("Missing values handled")

# Part 6: Baseline Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train_imp, y_train)

y_val_pred = dt.predict(X_val_imp)

print("Validation Accuracy:", accuracy_score(y_val, y_val_pred))

# Part 7: Hyperparameter tuning
param_grid = {
    "max_depth": [None, 3, 5, 7, 10],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "criterion": ["gini", "entropy"]
}

grid = GridSearchCV(
    DecisionTreeClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid.fit(X_train_imp, y_train)

print("Best parameters:", grid.best_params_)
best_dt = grid.best_estimator_

# Part 8: Test evaluation
y_test_pred = best_dt.predict(X_test_imp)
y_test_prob = best_dt.predict_proba(X_test_imp)[:,1]

print("Accuracy :", accuracy_score(y_test, y_test_pred))
print("Precision:", precision_score(y_test, y_test_pred))
print("Recall   :", recall_score(y_test, y_test_pred))
print("F1 Score :", f1_score(y_test, y_test_pred))
print("AUC      :", roc_auc_score(y_test, y_test_prob))

# Part 9: Confusion Matrix
cm = confusion_matrix(y_test, y_test_pred)

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Decision Tree")
plt.show()

# Part 10: ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_test_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_test_prob):.3f}")
plt.plot([0,1], [0,1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Decision Tree")
plt.legend()
plt.grid(True)
plt.show()

# Part 11: Decision Tree Visualization
plt.figure(figsize=(20,10))
plot_tree(
    best_dt,
    feature_names=X.columns,
    class_names=["No Disease", "Disease"],
    filled=True,
    rounded=True,
    max_depth=3
)
plt.title("Decision Tree Visualization (Depth â‰¤ 3)")
plt.show()

# Part 12: Sample predictions
sample_results = pd.DataFrame({
    "Actual": y_test.values[:10],
    "Predicted": y_test_pred[:10],
    "Probability": y_test_prob[:10]
})

sample_results

print("ðŸŽ‰ Decision Tree on heart.csv completed successfully â€” tree grew, marks too! ðŸŒ³ðŸ˜„")

